{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import urllib.request as request\n",
    "from contextlib import closing\n",
    "\n",
    "# first we download the Sift1M dataset\n",
    "with closing(request.urlopen('ftp://ftp.irisa.fr/local/texmex/corpus/sift.tar.gz')) as r:\n",
    "    with open('sift.tar.gz', 'wb') as f:\n",
    "        shutil.copyfileobj(r, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tarfile\n",
    "\n",
    "# the download leaves us with a tar.gz file, we unzip it\n",
    "tar = tarfile.open('sift.tar.gz', \"r:gz\")\n",
    "tar.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# now define a function to read the fvecs file format of Sift1M dataset\n",
    "def read_fvecs(fp):\n",
    "    a = np.fromfile(fp, dtype='int32')\n",
    "    d = a[0]\n",
    "    return a.reshape(-1, d + 1)[:, 1:].copy().view('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data we will search through\n",
    "xb = read_fvecs('./sift/sift_base.fvecs')  # 1M samples\n",
    "# also get some query vectors to search with\n",
    "xq = read_fvecs('./sift/sift_query.fvecs')\n",
    "# take just one query (there are many in sift_learn.fvecs)\n",
    "xq = xq[0].reshape(1, xq.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 128)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   3.,  11., 110.,  62.,  22.,   4.,   0.,  43.,  21.,  22.,\n",
       "         18.,   6.,  28.,  64.,   9.,  11.,   1.,   0.,   0.,   1.,  40.,\n",
       "        101.,  21.,  20.,   2.,   4.,   2.,   2.,   9.,  18.,  35.,   1.,\n",
       "          1.,   7.,  25., 108., 116.,  63.,   2.,   0.,   0.,  11.,  74.,\n",
       "         40., 101., 116.,   3.,  33.,   1.,   1.,  11.,  14.,  18., 116.,\n",
       "        116.,  68.,  12.,   5.,   4.,   2.,   2.,   9., 102.,  17.,   3.,\n",
       "         10.,  18.,   8.,  15.,  67.,  63.,  15.,   0.,  14., 116.,  80.,\n",
       "          0.,   2.,  22.,  96.,  37.,  28.,  88.,  43.,   1.,   4.,  18.,\n",
       "        116.,  51.,   5.,  11.,  32.,  14.,   8.,  23.,  44.,  17.,  12.,\n",
       "          9.,   0.,   0.,  19.,  37.,  85.,  18.,  16., 104.,  22.,   6.,\n",
       "          2.,  26.,  12.,  58.,  67.,  82.,  25.,  12.,   2.,   2.,  25.,\n",
       "         18.,   8.,   2.,  19.,  42.,  48.,  11.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 128  # dimensionality of Sift1M data\n",
    "k = 10  # number of nearest neighbors to return\n",
    "\n",
    "import faiss\n",
    "\n",
    "index = faiss.IndexFlatIP(d)\n",
    "index.add(xb)\n",
    "D, I = index.search(xq, k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, how can we make our search faster? There are two primary approaches:\n",
    "\n",
    "1) Reduce vector size — through dimensionality reduction or reducing the number of bits representing our vectors values.\n",
    "\n",
    "2) Reduce search scope — we can do this by clustering or organizing vectors into tree structures based on certain attributes, similarity, or distance — and restricting our search to closest clusters or filter through most similar branches.\n",
    "\n",
    "Solutions:\n",
    "\n",
    "1) Locality Sensitive Hashing\n",
    "2) Hierarchical Navigable Small World Graphs\n",
    "3) Inverted File Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locality Sensitive Hashing\n",
    "nbits = d*4  # resolution of bucketed vectors\n",
    "# initialize index and add vectors\n",
    "index = faiss.IndexLSH(d, nbits)\n",
    "index.add(xb)\n",
    "# and search\n",
    "D, I = index.search(xq, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical Navigable Small World Graphs\n",
    "# set HNSW index parameters\n",
    "M = 64  # number of connections each vertex will have\n",
    "ef_search = 32  # depth of layers explored during search\n",
    "ef_construction = 64  # depth of layers explored during index construction\n",
    "\n",
    "# initialize index (d == 128)\n",
    "index = faiss.IndexHNSWFlat(d, M)\n",
    "# set efConstruction and efSearch parameters\n",
    "index.hnsw.efConstruction = ef_construction\n",
    "index.hnsw.efSearch = ef_search\n",
    "# add data to index\n",
    "index.add(xb)\n",
    "\n",
    "# search as usual\n",
    "D, I = index.search(xb, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverted File Index\n",
    "nlist = 128  # number of cells/clusters to partition data into\n",
    "\n",
    "quantizer = faiss.IndexFlatIP(d)  # how the vectors will be stored/compared\n",
    "index = faiss.IndexIVFFlat(quantizer, d, nlist)\n",
    "index.train(xb)  # we must train the index to cluster into cells\n",
    "index.add(xb)\n",
    "\n",
    "index.nprobe = 8  # set how many of nearest cells to search\n",
    "D, I = index.search(xq, k)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "015cc5a99857e9fcd1ab0927880e4505b72089e0473c7b827a9368dc8509f23c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
